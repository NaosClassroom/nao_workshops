{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "783a8f95-aaa0-41ba-91bf-0a3ed555eeb7",
      "cell_type": "markdown",
      "source": "# 1. Intro to NAO\n\nHere, we will see how to connect to NAO and make him speak.\n\nFirst, we need to connect to NAO. Execute the code below.",
      "metadata": {}
    },
    {
      "id": "32222dc1-d15b-4912-9a88-bfc2c9b1128b",
      "cell_type": "code",
      "source": "%pip install ipywidgets==8.0.7  \n%pip install ipynao==0.8.9\n%pip install naowidgets==0.1.1\nimport asyncio\nimport ipynao\nfrom naowidgets import *\nnao = ipynao.Robot()\nnao.connect(\"nao.local\") # Set your IP address here\nnao",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "675c2f49-2510-4b79-8876-ea5b0766cd49",
      "cell_type": "markdown",
      "source": "Now, let's test the connection by making NAO speak:",
      "metadata": {}
    },
    {
      "id": "92e22395-3010-40e3-98f9-95b4b3a34b44",
      "cell_type": "code",
      "source": "show(nao.ALTextToSpeech.say(\"I am indeed connected\"))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "195604a9-48b9-42e9-a3f7-99b36b1274d1",
      "cell_type": "markdown",
      "source": "## 1.a - Making sure NAO is in the right state.\n\nWe need to make sure NAO's \"Autonomous Life\" is off, but that his motors are on. Execute these two cells:",
      "metadata": {}
    },
    {
      "id": "c2cadd32-e2df-4435-a94b-52f64f1a1b64",
      "cell_type": "code",
      "source": "show(nao.ALAutonomousLife.setState(\"disabled\"))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "a218e21e-60c0-4a79-a47d-efddddf9fd8f",
      "cell_type": "code",
      "source": "show(nao.ALMotion.wakeUp())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3909bd50-a006-406b-99ae-5e8c1cb642f3",
      "cell_type": "markdown",
      "source": "## 1.b - Animated Speech",
      "metadata": {}
    },
    {
      "id": "5122d3dd-9d09-4444-a4fd-e6a31f61868a",
      "cell_type": "markdown",
      "source": "Contrast these two calls:",
      "metadata": {}
    },
    {
      "id": "a6c79775-faa7-457c-9ec1-2bd51ded3ff1",
      "cell_type": "code",
      "source": "show(nao.ALTextToSpeech.say(\"This is with text to speech\"))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "7a215471-79ba-4be9-af57-4b4ed53d6ba3",
      "cell_type": "code",
      "source": "show(nao.ALAnimatedSpeech.say(\"And this is with animated speech\"))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "a12a4b5d-0867-48a3-b694-125d6f89d874",
      "cell_type": "code",
      "source": "show(nao.ALAnimatedSpeech.say(\"I refuse to do that. No way! I do not want to.\"))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "591141cf-c421-4a93-bd52-ff60c72ce725",
      "cell_type": "markdown",
      "source": "As you can see, with AnimatedSpeech, NAO will move his arms as he talks.",
      "metadata": {}
    },
    {
      "id": "cc793777-1f38-4a97-833a-696e1ef6ea75",
      "cell_type": "markdown",
      "source": "## 1.c - Tweaking NAO's voice\n\nYou can add **voice tags** - see [the documentation](http://doc.aldebaran.com/2-8/naoqi/audio/altexttospeech-tuto.html#using-tags-for-voice-tuning) for a full reference. Here are some examples:",
      "metadata": {}
    },
    {
      "id": "ad0529f2-68b3-444f-bd42-5c04e1b52bb8",
      "cell_type": "code",
      "source": "# Say the sentence with a pitch of +50%​\nshow(nao.ALAnimatedSpeech.say(\"\\\\vct=150\\\\Hello my friends\"))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "458b7883-6e33-45f0-bf6e-da5ea1fd24f9",
      "cell_type": "code",
      "source": "# Say the sentence 50% slower than normal speed​\nshow(nao.ALAnimatedSpeech.say(\"\\\\rspd=50\\\\hello my friends\"))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "35de606f-25df-4fd8-8718-9505ac23ad6f",
      "cell_type": "code",
      "source": "# Say the sentence with a volume of 50%\nshow(nao.ALAnimatedSpeech.say(\"\\\\vol=50\\\\Hello my friends\"))",
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "b241b257-3887-413a-8735-6047e26af8ee",
      "cell_type": "code",
      "source": "# Change the tone (available: normal, joyful, didactic)\nshow(nao.ALAnimatedSpeech.say(\"\\\\style=joyful\\\\ Today I am feeling happy.\"))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "c6b1b3ea-a872-468e-82a1-3872b6851c70",
      "cell_type": "code",
      "source": "# Reset with \\\\rst\\\\\nshow(nao.ALAnimatedSpeech.say(\"\\\\vct=150\\\\\\\\rspd=50\\\\Hello my friends.\\\\rst\\\\ How are you ?\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "238cf72a-f9e7-4e41-871f-a35296004c0b",
      "cell_type": "code",
      "source": "show(nao.ALAnimatedSpeech.say(\"(Your sentence here)\"))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "b059ad70-8914-49e0-828e-32e143cbe3ae",
      "cell_type": "markdown",
      "source": "## 1.d - Sequencing actions\n\nNow that we have learned how a few basic commands to make NAO speak, let's see a fgew more and how to combine them.\n\nTechnically, each call to a NAOqi function like ALTextToSpeech.say returns a \"coroutine\".\n\nSo far, we have used \"show\", which simply shows the result of one coroutine. If we want to sequence several, we can use \"as_widget\" like this:",
      "metadata": {}
    },
    {
      "id": "7ea4d48b-6aef-4930-8819-e14f33f83d0a",
      "cell_type": "code",
      "source": "@as_widget\nasync def try_leds(print):\n    await nao.ALAnimatedSpeech.say(\"Look at my eyes\")\n    await nao.ALLeds.rasta(2.0)\n    await nao.ALAnimatedSpeech.say(\"Not bad, right?\")\n    print(\"Done.\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "b8a1debb-99d3-4cef-a2a1-0c76c9bb2031",
      "cell_type": "markdown",
      "source": "Here's an example with even more commands. Now he we disable background movement to make sure NAO holds the pose as he speaks:",
      "metadata": {}
    },
    {
      "id": "36ece151-288f-4c5e-8b56-29e217e9d7cc",
      "cell_type": "code",
      "source": "@as_widget\nasync def little_speech(print):\n    await nao.ALAnimatedSpeech.say(\"So...\")\n    await nao.ALBackgroundMovement.setEnabled(False)\n    scratch_head = [-1.5187020301818848, 0.440216064453125, -0.14270401000976562, -1.3222661018371582, -1.3821759223937988, 0.00839996337890625]\n    await nao.ALMotion.angleInterpolationWithSpeed(\"LArm\", scratch_head, 0.5)\n    await nao.ALTextToSpeech.say(\"What's going on here?\")\n    await nao.ALBackgroundMovement.setEnabled(True)\n    print(\"Done.\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "63ce981b-0825-494c-b916-327270ac0750",
      "cell_type": "markdown",
      "source": "This can also be useful to get return values from functions:",
      "metadata": {}
    },
    {
      "id": "6d1bf720-68e0-4555-a016-a8a8c02a2006",
      "cell_type": "code",
      "source": "@as_widget\nasync def print_joints(print):\n    arm_joints = await nao.ALMotion.getJointNames(\"LArm\")\n    print(\"Arm joints:\", arm_joints)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "429cce8e-ee03-4745-b2fd-63ddc59376ad",
      "cell_type": "markdown",
      "source": "Here's an example with a loop:",
      "metadata": {
        "scrolled": true
      }
    },
    {
      "id": "681ce7a3-895f-4a12-b874-f3799ca81722",
      "cell_type": "code",
      "source": "@as_widget\nasync def list_languages(print):\n    languages = await nao.ALTextToSpeech.getAvailableLanguages()\n    print(\"Languages:\", languages)\n    await nao.ALAnimatedSpeech.say(f\"I can speak {len(languages)} languages\")\n    for language in languages:\n        await nao.ALAnimatedSpeech.say(language)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "1b824eb3-5339-4722-8a63-935b79c3d34c",
      "cell_type": "markdown",
      "source": "# 2 - Dialogue\n\nQiChat is a language for defining dialogues - what the robot can hear, what he can answer.",
      "metadata": {}
    },
    {
      "id": "d01cce9d-57a4-470f-9fb9-e143a3ad75db",
      "cell_type": "markdown",
      "source": "Using AI Chat requires Autonomous Life to be activated:",
      "metadata": {}
    },
    {
      "id": "01f717b5-c6f2-46da-a14e-47d70cd73897",
      "cell_type": "code",
      "source": "show(nao.ALAutonomousLife.setState(\"solitary\"))",
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f0d9fa4e-384b-4abe-9e5b-d90d23db03f9",
      "cell_type": "markdown",
      "source": "## 2.a A simple dialogue\n\nCreate the following dialogue:",
      "metadata": {}
    },
    {
      "id": "3890080c-8b81-4c5f-b0f5-b56acb3ff397",
      "cell_type": "code",
      "source": "show(nao.ALAIChat.set_topic(\"\"\"\nu:(hello) hello, sorry for not hearing you earlier it was my fault ?\n\nu:(what are we doing today?) We are programming a robot. I wonder who that is?\n\nu:(who are you?) I am NAO the little robot!\n\nu:(how are you) not that bad!\n\"\"\"))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0cc7a796-610b-43c5-90bc-7bb88da59329",
      "cell_type": "markdown",
      "source": "## 2.b Testing the dialogue\n\nTo switch to dialogue mode, press NAO's right bumper (that is, the one on your right). NOTE: this is a not a standard feature of NAO, but one added in this package to make testing this dialogue more convenient.\n\nYou can press the other bumper (to your right) to quit the app and return to Autonomous Life; note that this might trigger the robot's default dialogue if you have any installed, so be sure to keep track of the robot's state (recognizable by the blue feet).",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      }
    },
    {
      "id": "a7485b72-d586-473f-bd1a-c239cd0b6f62",
      "cell_type": "markdown",
      "source": "## 2.c More advanced dialogue\n\nNow that the basic dialogue works, you can try more advanced things - see [the documentation](http://doc.aldebaran.com/2-8/naoqi/interaction/dialog/dialog-syntax_full.html) for a full reference.",
      "metadata": {}
    },
    {
      "id": "fd9d318a-d721-4a4b-bed3-3ac6ba4eed6a",
      "cell_type": "code",
      "source": "nao.ALAIChat.set_topic(\"\"\"\nu:(I {really} like _[tea coffee]) Good to know $drink=$1\n\nu:(My name is _*) Pleased to meet you $1 $name=$1\n\nu:(Do you know me)\n ^first[\n   \"Yes, you are $name and you like $drink\"\n   \"Yes, you are $name\"\n   \"I know you like $drink\"\n   \"No, I don't know you\"\n ]\n\"\"\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "848ce7f6-63f1-421c-94f6-0db298bd7bed",
      "cell_type": "markdown",
      "source": "# 3 - AI Chat\n\nThis is more advanced chat, powered by OpenAI's services. It can be combined with qichat-based chat, and works the same way.\n\nYou can set a prompt with `ALAIChat.set_prompt`:",
      "metadata": {}
    },
    {
      "id": "f203321e-af64-45b7-b7a6-2d6497cafbc6",
      "cell_type": "code",
      "source": "show(nao.ALAIChat.set_prompt(\"\"\"\nYou are NAO, a friendly humanoid robot.\n\nYou are powered by ChatGPT but actually running on a physical NAO robot.\nNAO is used in education at all levels (primary to higher ed and research).\nNAO can be programmed with Choregraphe, Python, C++ and Jupyter Notebook.\nNAO is also sometimes used in retirement homes and special education.\n\nBe sure to speak in short simple sentences, like a child.\n\"\"\"))",
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "79310d57-05ce-4b95-a0a8-a52556ca5762",
      "cell_type": "code",
      "source": "show(nao.ALAIChat.set_prompt(\"\"\"\nYou are NAO, a friendly humanoid robot.\n\nYou are here to explain german idealism.\"\"\"))",
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "392bdf50-6d1d-4ef5-ab79-d58aa1de47e1",
      "cell_type": "code",
      "source": "show(nao.ALAIChat.set_prompt(\"\"\"\nYou are NAO, a friendly humanoid robot.\n\nYou are powered by ChatGPT but actually running on a physical NAO robot.\nYou are used in education at all levels (primary to higher ed and research).\n\nYou are in an elderly care institution, and can suggest exercise or ask people about their day.\n\nToday is tuesday, the families will visit this afternoon, and there is beans at the cafeteria.\n\nBe sure to speak in short simple sentences, like a child.\n\"\"\"))",
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "c6bbfb26-82ab-498a-a09c-ad642f949f84",
      "cell_type": "markdown",
      "source": "Once this is done, you can switch between qichat mode and \"AI mode\" by touching NAO's feet's bumpers: \n* The bumper to your left to enter AI mode (the feet should turn green)\n* The bumper to your right to return to qichat mode (the feet should be blue)\n\nWhen in AI mode, NAO will answer all your questions taking that prompt into account.",
      "metadata": {}
    },
    {
      "id": "a253958c-d996-4ea0-87ba-111a0da09df5",
      "cell_type": "markdown",
      "source": "## 3.b - Troubleshooting\n\nSometimes the robot will not answer. Some things to check\n\n1) Are the feet green ? If not, you might not be in the test app, try making sure Autonomous Life is activated and press the left foot bumper (blue feet), then again (green feet)\n\n2) Are the eyes blue ? If not, try restarting the test app (note that if the eyes are blue and not the feet, he's not using your dialogue, just a systme one)\n\n3) Is Free speech active ? You can try with this dialogue:",
      "metadata": {}
    },
    {
      "id": "9fe7058e-a896-457d-a421-06d2dbc497c2",
      "cell_type": "code",
      "source": "show(nao.ALAIChat.set_topic(\"\"\"\nu:(repeat _*) you said $1\n\nu:(are you listening) I think so, yes\n\"\"\"))",
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "00c75e2b-2ba1-4704-97ce-bf77274b813c",
      "cell_type": "markdown",
      "source": "If it doesn't work, it could be a network connection problem or, more likely, that Free Speech is not activated on your robot. If it used to work but doesn't anymore, rebooting NAO could help.",
      "metadata": {}
    },
    {
      "id": "d511731b-b886-4e0c-8345-0332d98ee984",
      "cell_type": "code",
      "source": "show(nao.ALAIChat.answer(\"Hey NAO, what do you think of that movie concept?\"))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "b93ae320-efec-436d-9fd3-d7e334801c93",
      "cell_type": "markdown",
      "source": "# 4 - Motion\n\nNow let's make NAO move! This can be done in several ways: joint control and motion control.\n\nBut first, we should disable life and wake up (i.e. turn all motors on):",
      "metadata": {}
    },
    {
      "id": "6be7ff3e-a9b3-4f29-81b0-715dd2e94b2a",
      "cell_type": "code",
      "source": "@as_widget\nasync def prepare_for_motion(print):\n    await nao.ALAutonomousLife.setState(\"disabled\")\n    await nao.ALMotion.wakeUp()\n    print(\"NAO should be ready for motion control!\")\n    ",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "6bdeeb95-a29e-4ca5-84a2-66d65ea6bf33",
      "cell_type": "markdown",
      "source": "## 4.a - Joint control\n\nThe `ALMotion` service allows to control individual joints: their stiffness, and their angles.\n\nFor example, let's make NAO take a \"scratch his head\" pose:",
      "metadata": {}
    },
    {
      "id": "1d34f908-0142-41a7-bba9-56732a283d13",
      "cell_type": "code",
      "source": "scratch_head = [-1.5187020301818848, 0.440216064453125, -0.14270401000976562, -1.3222661018371582, -1.3821759223937988, 0.00839996337890625]\nshow(nao.ALMotion.setAngles(\"LArm\", scratch_head, 0.5))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "1fc1ce82-2f9f-4d02-9e47-187e15ad0176",
      "cell_type": "code",
      "source": "hand_on_hip = [1.4495880603790283, 0.817579984664917, 0.07512402534484863, -1.5585020780563354, -1.8362398147583008, 0.011199951171875]\nshow(nao.ALMotion.setAngles(\"LArm\", hand_on_hip, 0.5))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "43ecf97a-a1df-47e8-b7c0-b94261517c23",
      "cell_type": "markdown",
      "source": "Instead of setAngles, one can use `angleInterpolationWithSpeed`, which gives a slightly nice movement:",
      "metadata": {}
    },
    {
      "id": "f9651879-bba9-4b76-b3a9-a280a3ca3139",
      "cell_type": "code",
      "source": "show(nao.ALMotion.angleInterpolationWithSpeed(\"LArm\", scratch_head, 0.5))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0197f2a8-e190-4eba-84aa-3da5e3e836e9",
      "cell_type": "markdown",
      "source": "## 4.b - Dedicated control widgets\n\nUsing a dedicated widget can make arm control easier. With this Arm Controller widget, you can set a series of poses:",
      "metadata": {}
    },
    {
      "id": "db7053a7-8348-4d7b-833d-bee68250ce35",
      "cell_type": "code",
      "source": "larm = LeftArmController(nao)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "a60a674f-f07d-488a-a4ba-ce25361bf2ca",
      "cell_type": "markdown",
      "source": "A more advanced widget can control the whole torso:",
      "metadata": {}
    },
    {
      "id": "b4ad1b62-2bab-466f-a937-cd5f038bd0f7",
      "cell_type": "code",
      "source": "torso = NaoTorsoController(nao)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "078b6df2-e51a-45b9-a4c3-9e01d256e6bc",
      "cell_type": "markdown",
      "source": "## 4.c - Walking around\n\nYou can make NAO walk around with ALMotion.moveTo (x, y, theta) where x is forward.\n\nWARNING: do not do this if NAO is on a table!",
      "metadata": {}
    },
    {
      "id": "e0c14f4b-2b0a-470c-8b6f-224254519aec",
      "cell_type": "code",
      "source": "show(nao.ALMotion.moveTo(0.5, 0., 0.0))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "010af222-004f-4598-a8d8-90e127b583e1",
      "cell_type": "markdown",
      "source": "# 5 - AI-driven actions\n\nNow, let's get back to ChatGPT. So far, we have only used it in a straightforward way, to make NAO speak. But actually, it can also send back **commands** that NAO can execute, to make him move, walk, etc.",
      "metadata": {}
    },
    {
      "id": "bc316d72-366a-43e3-939b-5aa323be8941",
      "cell_type": "markdown",
      "source": "## 5.a - Discovering action tools\n\nThese commands correspond to **tools** and tools can be activated on `ALAIChat`. You can see which ones are available with `ALAIChat.get_available_tools()`.",
      "metadata": {}
    },
    {
      "id": "12a16a4b-d817-4b24-959c-572292bd2f2c",
      "cell_type": "code",
      "source": "show(nao.ALAIChat.get_available_tools())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "2d6a2af5-533e-4289-b86f-7223d9fd1137",
      "cell_type": "markdown",
      "source": "You can activate / deactivate tools with `ALAIChat.activate_tool` and `ALAIChat.deactivate_tool`. For example, let's activate \"rasta\", which is a useful one for testing.",
      "metadata": {}
    },
    {
      "id": "f85344ca-75c2-48e4-a16a-0dbb6f7b3d31",
      "cell_type": "code",
      "source": "show(nao.ALAIChat.activate_tool(\"rasta\"))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "30485bd6-63da-45c6-a67e-bda8ba391870",
      "cell_type": "markdown",
      "source": "You can then try this by switching to AI mode ... but you can also try directly sending a command to the robot, useful for testing:",
      "metadata": {}
    },
    {
      "id": "6d219e7d-3247-4948-aea9-6af2fafe0440",
      "cell_type": "code",
      "source": "show(nao.ALAIChat.answer(\"Make your LEDs move for a few seconds in a rasta pattern.\"))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "795819a7-e2ff-48e0-a729-c16c3093733e",
      "cell_type": "markdown",
      "source": "Note that a useful tool to activate is \"say\", as that one allows an answer that treats speech as an action that can be mixed among the others:",
      "metadata": {}
    },
    {
      "id": "8ae924b4-692b-4481-8d62-a1414a643fc9",
      "cell_type": "code",
      "source": "show(nao.ALAIChat.activate_tool(\"change_posture\"))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "a9895720-5b71-4cb9-a1a5-2c301df2dd87",
      "cell_type": "markdown",
      "source": "## 5.b - Combining several tools\n\nTool calls can be combined; let's activate much more:",
      "metadata": {}
    },
    {
      "id": "fb9e3407-46ad-478b-ab31-5e821eaed95d",
      "cell_type": "code",
      "source": "show(nao.ALAIChat.set_prompt(\"Your are a simple, obedient robot. You can perform actions with tool calls (say, rasta, think), including several in a row. When speeking, stay very short.\"))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "35564eb5-8762-4a2f-95f8-fda4fef27e46",
      "cell_type": "code",
      "source": "#TOOL_TO_ACTIVATE = [\"rasta\", \"say\", \"think\", \"play_animation\", \"change_posture\", \"custom_pose\"]\nTOOL_TO_ACTIVATE = [\"rasta\", \"say\", \"think\"]\n\n@as_widget\nasync def activate_tools(print):\n    for tool_name in TOOL_TO_ACTIVATE:\n        success = await nao.ALAIChat.activate_tool(tool_name)\n        print(\"Activate\", tool_name, \"status:\", success)\n    print(\"Done with activating tools\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0678ae2e-8d34-4434-bf9c-0bf2b6bcaa58",
      "cell_type": "markdown",
      "source": "You can try these out directly with `ALAIChat.answer`:",
      "metadata": {}
    },
    {
      "id": "2bf3b293-bb23-4b8e-9512-e9dde2fd5d83",
      "cell_type": "code",
      "source": "show(nao.ALAIChat.answer(\"Count to three, for each one alternating between saying that number and doing a rasta eye pattern for that many seconds.\"))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d544a3fa-75b8-4aa2-b4ba-5c325e562664",
      "cell_type": "markdown",
      "source": "You can use this function to inspect what the robot did:",
      "metadata": {}
    },
    {
      "id": "c62800cd-1b04-4f71-b63f-80c02713e9b5",
      "cell_type": "code",
      "source": "show(nao.ALAIChat.get_printable_last_actions())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ec7671f0-6816-4d80-b4d9-ad22752689f3",
      "cell_type": "code",
      "source": "show(nao.ALAIChat.get_active_tools())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3585b23a-d2b6-4551-8055-a16146178c98",
      "cell_type": "markdown",
      "source": "You can experiment a bit with the other tools, for example, use `move_to` to make a NAO that can walk around.\n\nYou can deactivate tools with this:",
      "metadata": {}
    },
    {
      "id": "8fd2f34b-2b76-4938-b884-c0ca14d9e56a",
      "cell_type": "code",
      "source": "@as_widget\nasync def deactivate_tools(print):\n    for tool_name in await nao.ALAIChat.get_active_tools():\n        success = await nao.ALAIChat.deactivate_tool(tool_name)\n        print(\"Deactivate\", tool_name, \"status:\", success)\n    print(\"Done with deactivating tools\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "7aa04c56-67bb-4b49-b711-6a1096858252",
      "cell_type": "markdown",
      "source": "## 5.c - Simple custom poses\n\n`custom_pose` is a special tool that allows you to nbame and define your own pose, that can then be triggered by the LLM.\n\nYou can do that with `ALAIChat.add_custom_pose` that takes as parameter:\n - the name you want to give the pose - this one is important, because that's how\n - the list of joints\n - a list of poses, each of which should be she same size as the list of joints.\n\nFor example:",
      "metadata": {}
    },
    {
      "id": "5c35b8ce-4f28-47c6-878c-e288357ef3a8",
      "cell_type": "code",
      "source": "show(nao.ALAIChat.add_custom_pose(\"shake head\", [\"HeadYaw\"], [[-1.0], [1.0], [.0]]))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "07eb8020-063d-4528-8603-eb3263f0778c",
      "cell_type": "markdown",
      "source": "If you haven't already, be sure to activate the custom pose tool:",
      "metadata": {}
    },
    {
      "id": "efb022bb-8c5d-446d-9850-b37b77ac7452",
      "cell_type": "code",
      "source": "show(nao.ALAIChat.activate_tool(\"custom_pose\"))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "fe6ca5a1-1fd0-45d3-a0a3-a01c0742f5d1",
      "cell_type": "markdown",
      "source": "You can now ask NAO to shake his head, either directly or with this command:",
      "metadata": {}
    },
    {
      "id": "a0459647-ea1d-43f2-9252-24f6636b2298",
      "cell_type": "code",
      "source": "show(nao.ALAIChat.answer(\"Say something sad, then shake your head.\"))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f0298316-d549-4d6d-88f3-60def3a89ac3",
      "cell_type": "markdown",
      "source": "## 5.d - More custom poses\n\nOf course, manually defining each single joint can be quite some cumbersone; so instead let's use the torso control widget we used earlier.\n\nBut first, let's make a helper function to disable/enable autonomous abilities:",
      "metadata": {}
    },
    {
      "id": "72bdd2a0-20d4-4485-9038-6e5dba96f6cc",
      "cell_type": "code",
      "source": "enabled = True\n@as_widget\nasync def set_abilities(print):\n    print(\"Setting abilities enabled=\", enabled)\n    await nao.ALBackgroundMovement.setEnabled(enabled)\n    await nao.ALListeningMovement.setEnabled(enabled)\n    await nao.ALBasicAwareness.setEnabled(enabled)\n    print(\"Setting abilities done\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d51d914e-7476-4b5f-9592-083f8816bbf6",
      "cell_type": "markdown",
      "source": "Now let's create our widget:",
      "metadata": {}
    },
    {
      "id": "7dcb1f4b-0407-4161-b336-a501238127b4",
      "cell_type": "code",
      "source": "torso = NaoTorsoController(nao)",
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "fce82dd8-c9ab-480b-bcd4-6a5f15661d91",
      "cell_type": "markdown",
      "source": "You can the this widget to define a pose, and save it here:",
      "metadata": {}
    },
    {
      "id": "e424f35b-8734-4f02-b95b-5a68f87fd3ff",
      "cell_type": "code",
      "source": "show(nao.ALAIChat.add_custom_pose(\"show off\", torso.all_joints, torso.poses))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "07a0fb55-85f2-43ce-9265-f30bc6424a45",
      "cell_type": "markdown",
      "source": "You can now create any number of poses, and the LLM will be capable of using them.",
      "metadata": {}
    },
    {
      "id": "8be69c42-df3d-4de2-a2f6-cf724ef57824",
      "cell_type": "markdown",
      "source": "# 6 - Non-speech inputs",
      "metadata": {}
    },
    {
      "id": "c7516903-610a-4ece-8537-cb9107b450ee",
      "cell_type": "markdown",
      "source": "NAO's default action loop is listening for speech, then answering accordingly.\n\nFor this section, we will stop using dialogue, and use NAO's sensors instead.\n\nTo do that, let's stop AutonomousLife, so that NAO will not listen any more:",
      "metadata": {}
    },
    {
      "id": "ba184766-f1ec-47ed-9658-b79f0d2b724f",
      "cell_type": "code",
      "source": "@as_widget\nasync def stopLife(print):\n    await nao.ALAutonomousLife.setState(\"disabled\")\n    await nao.ALMotion.wakeUp()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3e3ea714-c40e-4c66-a550-004ceb2db2dd",
      "cell_type": "markdown",
      "source": "## 6.a Manually triggering with a system message\n\nHere instead of `answer` we will use `answer_sysem_message`, which is similar but used to describe what the robot perceived, still as English. But NAO will not treat answer it as if it was dialogue.",
      "metadata": {}
    },
    {
      "id": "9a465c9f-f5ba-4d08-9c1c-0267fb599803",
      "cell_type": "code",
      "source": "show(nao.ALAIChat.answer_system_message(\"You are now alone. Time elapsed=25s.\"))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3a02d5d0-dbcc-446d-a2af-22271d4e3dea",
      "cell_type": "markdown",
      "source": "## 6.b Your own loop.\n\nYou can then use this to create your own interaction loop, for example this one, that will make NAO walk around.\n\nMake sure to put him on the ground first!",
      "metadata": {}
    },
    {
      "id": "1bb308f0-0c0f-4d00-a3c1-2811c533d6de",
      "cell_type": "code",
      "source": "@as_widget\nasync def sonarLoop(print):\n    for i in range(5):        \n        left = await nao.ALMemory.getData(\"Device/SubDeviceList/US/Left/Sensor/Value\")\n        right = await nao.ALMemory.getData(\"Device/SubDeviceList/US/Right/Sensor/Value\")\n        context_desc = f\"Left sonar: {left:.1f}m, Right sonar: {right:.1f}m\"\n        print(\"Context:\", context_desc)\n        r = await nao.ALAIChat.answer_system_message(context_desc)\n        print(f\"Step {i} success: {r}\")\n        actions = await nao.ALAIChat.get_printable_last_actions()\n        print(actions)\n        await nao.ALRobotPosture.goToPosture(\"Stand\", 0.5) # Make sure the robot ends in a good posture\n    await nao.ALTextToSpeech.say(\"loop done\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "b5187dda-06f9-4b12-af26-dd72a943d191",
      "cell_type": "markdown",
      "source": "## 6.c Other sensors\n\nIn this loop, we use sensors, but you could actually collect a lot of information, such as:\n\n * NAO's (estimated) position in the world [ALMotion.getPosition](http://doc.aldebaran.com/2-8/naoqi/motion/control-cartesian-api.html#ALMotionProxy::getPosition__ssCR.iCR.bCR)\n * Detected people: with [PeoplePerception](http://doc.aldebaran.com/2-8/naoqi/peopleperception/alpeopleperception-api.html#events-lists)\n * Detected people's face expressions with [ALGazeAnalysis](http://doc.aldebaran.com/2-8/naoqi/peopleperception/algazeanalysis.html#algazeanalysis) and [ALFaceCharacteristics](http://doc.aldebaran.com/2-8/naoqi/peopleperception/alfacecharacteristics.html#alfacecharacteristics)\n * NAO's standing / sitting pose with [ALRobotPosture](http://doc.aldebaran.com/2-8/naoqi/motion/alrobotposture.html)",
      "metadata": {}
    }
  ]
}